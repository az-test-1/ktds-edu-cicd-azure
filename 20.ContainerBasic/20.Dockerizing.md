# Docker Build



# 1. 개요

Docker Build



# 2. Dockerfile

Maven을 사용하여 Java 애플리케이션을 빌드를 포함한 Docker File 생성



## 1) Dockerfile

```Dockerfile
# Stage 1: Build the application using Maven
FROM maven:3.8.5-openjdk-17-slim AS build

# Set the working directory inside the container
WORKDIR /app

# Copy the pom.xml and download the dependencies
COPY pom.xml ./
RUN mvn dependency:go-offline

# Copy the entire source code
COPY src ./src

# Package the application
RUN mvn clean package -DskipTests

# Stage 2: Create a smaller, final image
FROM openjdk:17-jdk-slim

# Set the working directory inside the container
WORKDIR /app

# Copy the JAR file from the build stage
COPY --from=build /app/target/healthcheck*.jar /app/healthcheck.jar

# Expose the application port
EXPOSE 8080

# Define the command to run the application
CMD ["java", "-jar", "/app/healthcheck.jar"]
```

## 2) 단계별 설명

1. **Stage 1: Build Stage**

   - **Base Image:** `maven:3.8.5-openjdk-17-slim` 이미지를 사용. 이 이미지는 Maven과 OpenJDK 17이 설치되어 있음

   - **Working Directory:** `/app` 디렉토리를 작업 디렉토리로 설정

   - **Dependency Caching:** `pom.xml` 파일을 먼저 복사하고 `mvn dependency:go-offline`을 실행하여 종속성을 캐시한다. 이를 통해 빌드 속도를 높이고, 소스 코드가 변경되지 않은 경우 종속성을 다시 다운로드하지 않음.

     프로젝트의 모든 의존성 및 플러그인을 미리 다운로드하여, 이후 **오프라인 환경**에서도 Maven 작업이 원활히 실행되도록 준비

   - **Build:** `mvn clean package -DskipTests` 명령어를 실행하여 테스트를 건너뛰고 애플리케이션을 빌드. 이 단계에서 `target/` 디렉토리에 JAR 파일이 생성

2. **Stage 2: Final Image**

   - **Base Image:** `openjdk:17-jdk-slim` 이미지를 사용. 이 이미지는 JDK만 포함된 경량 이미지
   - **Copy Artifacts:** 첫 번째 단계에서 생성된 JAR 파일을 최종 이미지의 `/app/` 디렉토리에 복사
   - **Expose Port:** 애플리케이션이 사용하는 포트(예: 8080)를 외부에 노출
   - **CMD:** `java -jar` 명령어를 사용하여 JAR 파일을 실행



## 3) 사용 방법

이 Dockerfile을 프로젝트 루트 디렉토리에 저장한 후, Docker 이미지를 빌드하고 실행

```bash
docker build -t healthcheck .
docker run -p 8080:8080 healthcheck
```

이제 Docker 컨테이너에서 Java 애플리케이션이 실행되며, 호스트 머신의 포트 8080에서 접근





# 3. 실습

Sample Source 를 Clone 하여 Build 후 Push 해 보자.



## 1) Git Clone

```sh
$ cd ~/githubrepo

$ git clone https://github.com/ssongman/SampleJava.git

```



## 2) Build

```sh
$ cd ~/githubrepo/SampleJava

# Image build
$ docker build -t axcoe/samplejava:v1.0 .
$ docker build -t axcoe/samplejava:v1.1 .

```



## 3) Run

```sh
# Docker run
$ docker run -d --name samplejava -p 8080:8080 axcoe/samplejava:v1.0

# Docker ps
$ docker ps -a
CONTAINER ID   IMAGE                   COMMAND               CREATED         STATUS         PORTS                                       NAMES
63fb323aaa5f   axcoe/samplejava:v1.0   "java -jar app.jar"   7 seconds ago   Up 6 seconds   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp   samplejava


# Test
$ curl localhost:8080/health -i

HTTP/1.1 200
Content-Type: text/plain;charset=UTF-8
Content-Length: 17
Date: Sat, 28 Sep 2024 05:22:11 GMT

Server is running

# test 결과 200 Code 가 리턴된다.


```





## 4) Push

### (1) ACR login 정보 확인

```sh

$ az acr list -o table
NAME          RESOURCE GROUP    LOCATION      SKU      LOGIN SERVER             CREATION DATE         ADMIN ENABLED
------------  ----------------  ------------  -------  -----------------------  --------------------  ---------------
tiurefappcr   tiu-ref-com-rg    koreacentral  Premium  tiurefappcr.azurecr.io   2024-09-09T03:56:30Z  True
tiurefbasecr  tiu-ref-com-rg    koreacentral  Premium  tiurefbasecr.azurecr.io  2024-09-09T03:56:30Z  True



ACR_NAME=tiurefappcr
RESOURCE_GROUP=tiu-ref-com-rg


$ az acr credential show --name $ACR_NAME --resource-group $RESOURCE_GROUP

{
  "passwords": [
    {
      "name": "password",
      "value": "Mfwtosguxk9r04J0goXAyt2B22cUr8kygnW2t3oUmX+ACRDeKjYC"
    },
    {
      "name": "password2",
      "value": "sHkK8cFs/ZhaLFpsNVoHBPv3G0j3LHSgRtJadlgs7W+ACRBkojOV"
    }
  ],
  "username": "tiurefappcr"
}


```



### (2) login, tag, push

```sh
ACR_SERVER=tiurefappcr.azurecr.io


# Docker login
$ docker login tiurefappcr.azurecr.io --username tiurefappcr
Password:
Login Succeeded

# Mfwtosguxk9r04J0goXAyt2B22cUr8kygnW2t3oUmX+ACRDeKjYC


# Docker tag
$ docker tag  axcoe/samplejava:v1.0 tiurefappcr.azurecr.io/axcoe/samplejava:v1.0

# push 
$ docker push tiurefappcr.azurecr.io/axcoe/samplejava:v1.0

```





## 5) Clean up

```sh
# Delete Container 
$ docker rm -f samplejava

# Delete image 
$ docker rmi axcoe/samplejava:v1.0
  docker rmi axcoe/samplejava:v1.1

```







# Docker Buildx





# 1. Docker Buildx란?



**Docker Buildx**는 Docker의 확장 기능으로, 기본 빌드 명령어보다 더 강력한 빌드 기능을 제공한다. Buildx는 다음과 같은 기능을 포함한다.



* **멀티 플랫폼 빌드**: 하나의 Dockerfile로 여러 플랫폼에 맞는 이미지를 동시에 빌드.
* **외부 빌더(Builder)**: 로컬에서 직접 빌드하지 않고도 외부 클러스터를 통해 빌드 작업을 수행.
* **캐시 내보내기/가져오기**: 빌드 캐시를 내보내고 가져와 빌드 속도를 높임.



# 2. [Buildx] 멀티 플랫폼 빌드

docker buildx를 사용하여 멀티 플랫폼 빌드를 지원하는 Docker 이미지를 생성할 수 있다. 



## 1) **멀티 플랫폼 빌드가 필요한 이유**

오늘날 다양한 하드웨어 아키텍처가 사용되면서, 멀티 플랫폼 지원이 중요해졌다. 특히, 서버에서는 대부분 **x86_64** 기반이지만, 모바일 기기나 일부 개발 환경에서는 **ARM** 기반의 아키텍처도 사용된다. 애플의 M1/M2 칩은 ARM 기반이기 때문에, ARM 아키텍처를 지원하는 Docker 이미지를 빌드할 필요가 있다.

멀티 플랫폼 빌드는 이러한 문제를 해결하고, 애플리케이션이 다양한 플랫폼에서 실행될 수 있도록 한다.



## 2) 빌더 활성화

```sh
$ docker buildx create --use
upbeat_matsumoto


$ docker buildx  ls
NAME/NODE               DRIVER/ENDPOINT     STATUS     BUILDKIT   PLATFORMS
upbeat_matsumoto*       docker-container
 \_ upbeat_matsumoto0    \_ desktop-linux   inactive
default                 docker
 \_ default              \_ default         running    v0.13.2    linux/arm64, linux/amd64, linux/amd64/v2, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6
desktop-linux           docker
 \_ desktop-linux        \_ desktop-linux   running    v0.13.2    linux/arm64, linux/amd64, linux/amd64/v2, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/mips64le, linux/mips64, linux/arm/v7, linux/arm/v6



$ docker buildx create --use
clever_varahamihira

$ docker buildx ls
NAME/NODE                  DRIVER/ENDPOINT                   STATUS     BUILDKIT   PLATFORMS
clever_varahamihira*       docker-container
 \_ clever_varahamihira0    \_ unix:///var/run/docker.sock   inactive
default                    docker
 \_ default                 \_ default                       running    v0.16.0    linux/amd64, linux/amd64/v2, linux/amd64/v3, linux/386
song@eduVM:~/githubrepo/SampleJava$


```



## 3) **멀티 플랫폼 빌드 실행**

```sh
$ docker buildx build \
    --platform linux/amd64,linux/arm64 \
    -t edu01/samplejava:latest \
    --push .

```

* --platform linux/amd64,linux/arm64: 여러 플랫폼용으로 이미지를 빌드 (멀티아키텍처 지원).
* -t my-spring-app:latest: 생성된 Docker 이미지에 my-spring-app:latest 태그를 추가
* --push: 빌드가 완료되면 이미지를 Docker Registry (예: Docker Hub)로 푸시
  * push 옵션은 필수이다.
  * 없으면 아래와 같은 에러 발생
    * No output specified with docker-container driver. Build result will only remain in the build cache. To push result image into registry use --push or to load image into docker use --load



## 4) 확인

멀티 플랫폼 빌드가 완료되면, docker manifest inspect 명령어로 이미지가 여러 아키텍처로 빌드되었는지 확인할 수 있다

```sh
$ docker manifest inspect edu01/samplejava:latest

```





# 3. [Buildx] 빌드 캐시 사용

docker buildx는 빌드 캐시를 내보내고 가져오는 기능을 제공된다.

이전 빌드의 캐시를 재사용하여 빌드 시간을 단축할 수 있다.



## 1) Buildx 캐시 샘플

```sh
$ docker buildx build \
    --cache-from=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache \
    --cache-to=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache,mode=max \
    --push \
    -t tiurefappcr.azurecr.io/song/samplejava:v1.0 .

```

이전 빌드의 캐시를 재사용하여 빌드 시간을 단축할 수 있다.



* cache from/to

  * **캐시 가져오기**: --cache-from=type=registry,ref=myrepo/myimage:cache로 이전에 저장된 캐시를 레지스트리에서 가져온다.

  * **캐시 저장**: --cache-to=type=registry,ref=myrepo/myimage:cache,mode=max로 빌드 후 최대한의 캐시 정보를 레지스트리에 저장한다.

* cache type : 빌드 캐시 저장 옵션

  * **local**: 로컬 파일 시스템에 캐시를 저장한다.
    * 예시: --cache-to=type=local,dest=/path/to/cache

  * **inline**: 이미지에 캐시 메타데이터를 내장시킨다. 이 방식은 이미지 자체에 캐시 정보를 저장하므로, 다른 환경에서도 이미지를 가져올 때 캐시를 사용할 수 있다.
    * 예시: --cache-to=type=inline
  * **registry**: Docker 레지스트리에 캐시를 저장한다. 이 방식은 레지스트리 기반의 빌드 환경에서 유용하다.
    * 예시: --cache-to=type=registry,ref=myrepo/myimage:cache

  * **s3**: AWS S3와 같은 외부 스토리지에 캐시를 저장할 수 있다.
    * 예시: --cache-to=type=s3,bucket=mybucket,region=us-west-2


* cache mode : 캐시 최적화 옵션

  * 캐시를 저장할 때 mode 옵션을 통해 캐시 크기를 제어할 수 있다.

  * min: 필요한 최소한의 캐시만 저장


  * max: 가능한 모든 캐시 데이터를 저장하여, 최대한 많은 빌드 데이터를 재사용할 수 있도록 한다.






## 2) Cache 소요시간 분석

소요시간 측정을 위해 time 을 붙여서 테스트해보자.

### (1) 1st Build

캐시기능을 활용하지 않고 docker build 수행시 소요되는 시간을 체크한다.

```sh
# Docker 빌드 캐시 삭제
$ docker builder prune -f

# Docker 빌드 명령
$ time docker build --no-cache -t tiurefappcr.azurecr.io/song/samplejava:v1.0 .
real    1m53.438s
user    0m2.664s
sys     0m1.686s


```

* Build 작업 : 1분 53초 소요됨



### (2) 2nd Build

cache 가 없을때 Build&Push 소요시간을 체크한다.

```sh
# docker image 삭제
$ docker rmi tiurefappcr.azurecr.io/song/samplejava:v1.0

# Docker 빌드 캐시 삭제
$ docker builder prune -f


# build
$ time \
  docker buildx build --no-cache \
    --cache-to=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache,mode=max \
    --push \
    -t tiurefappcr.azurecr.io/song/samplejava:v1.0 \
    -t tiurefappcr.azurecr.io/song/samplejava:latest \
    .

# 소요시간
real    1m51.905s
user    0m2.659s
sys     0m1.413s



# acr 확인
$ az acr repository show-tags --name tiurefappcr --repository song/samplejava
[
  "cache",
  "latest",
  "v1.0"
]


```

* Build & Push 작업에 1분 51초가 소요됨





### (3) 3th build

Cache 사용시 Build&Push 소요시간을 체크한다.

```sh
# build
$ time \
  docker buildx build \
    --cache-from=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache \
    --cache-to=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache,mode=max \
    --push \
    -t tiurefappcr.azurecr.io/song/samplejava:v1.1 \
    -t tiurefappcr.azurecr.io/song/samplejava:latest \
    .
    
# 소요시간
real    0m8.858s
user    0m0.156s
sys     0m0.062s


# acr 확인
$ az acr repository show-tags --name tiurefappcr --repository song/samplejava
[
  "cache",
  "latest",
  "v1.0",
  "v1.1"
]

```

* Build & Push 작업에 8초가 소요됨





## 3) [참고] load 옵션

Docker에서 buildx 명령을 사용하여 이미지를 빌드하고 푸시할 때, 기본적으로 빌드된 이미지는 로컬에 저장되지 않는다. 로컬에 이미지를 생성하려면 --load 또는 --output 옵션을 사용해야 한다.

### (1) Build

```sh
# push, load 모두 사용
docker buildx build \
    --cache-from=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache \
    --cache-to=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache,mode=max \
    --push \
    --load \
    -t tiurefappcr.azurecr.io/song/samplejava:v1.1 .

# push 없이 load 만 : registry 에 push 는 안된다.
docker buildx build \
    --cache-from=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache \
    --cache-to=type=registry,ref=tiurefappcr.azurecr.io/song/samplejava:cache,mode=max \
    --load \
    -t tiurefappcr.azurecr.io/song/samplejava:v1.2 .
    
```

* --load 옵션은 멀티 플랫폼 빌드를 지원하지 않는다. 단일 플랫폼(--platform linux/amd64)에서만 작동한다.



### (2) 컨테이너 실행

```sh
# Docker 컨테이너 실행
$ docker run -d --name samplejava -p 8080:8080 tiurefappcr.azurecr.io/song/samplejava:v1.0

# test
# 다른 터미널에서...
$ curl localhost:8080/health -i

# 삭제
$ docker rm -f samplejava

```





# 4. [참고] Dockerizing



## 1) Dockerfile

```yaml
# Stage 1: Build the application using Maven
FROM maven:3.8.4-openjdk-17 AS build
WORKDIR /app
COPY pom.xml .
COPY src ./src
RUN mvn clean package -DskipTests


# Stage 2: Run the application using OpenJDK
FROM openjdk:17-jdk-slim
WORKDIR /app
COPY --from=build /app/target/*.jar app.jar
EXPOSE 8080
ENTRYPOINT ["java", "-jar", "app.jar"]

```





## 2) Docker build 및 실행

```sh
# Docker 빌드 명령
$ docker build -t tiurefappcr.azurecr.io/song/samplejava:v1.3 .


# Docker 컨테이너 실행
$ docker run -p 8080:8080 my-spring-app

# test
# 다른 터미널에서...
$ curl localhost:8080/health -i

```









